package json
{
  "dependencies": {
    "express": "^4.18.2",
    "archiver": "^6.0.1",
    "pdfkit": "^0.13.0",
    "cheerio": "^1.0.0-rc.12",
    "axios": "^1.6.0"
  },
  "devDependencies": {
    "@types/express": "^4.17.17",
    "@types/archiver": "^6.0.0",
    "@types/pdfkit": "^0.13.0",
    "@types/node": "^20.8.9"
  }
}

shared Schema

// The Job data sent from the frontend to /api/download
export interface DownloadJob {
  novel: NovelMetadata;
  chapters: Chapter[];
  fileType: 'epub' | 'pdf';
}

export interface NovelMetadata {
  title: string;
  author: string;
  coverUrl: string;
}

// We REMOVE `content?: string`.
// The backend will fetch the content one by one.
export interface Chapter {
  title: string;
  url: string;
}

shared route ts

import express, { Router, Request, Response } from 'express';
import { streamEpub, streamPdf } from './generator';
import { DownloadJob } from '../shared/schema';

const router = Router();

// 1. Increase Express request size limits.
// This is a "band-aid" for the job metadata, but the real fix is
// not sending chapter content from the client at all.
router.use(express.json({ limit: '50mb' }));
router.use(express.urlencoded({ extended: true, limit: '50mb' }));

/**
 * @route POST /api/download
 * Receives the job details (chapter list, metadata) and
 * immediately begins streaming the file generation.
 */
router.post('/api/download', async (req: Request, res: Response) => {
  try {
    const { novel, chapters, fileType } = req.body as DownloadJob;

    if (!novel || !chapters || !chapters.length || !fileType) {
      return res.status(400).json({ error: 'Missing required job data.' });
    }

    // Sanitize filename
    const filename = novel.title.replace(/[^a-z0-9_ \-]/gi, '_').replace(/ /g, '_');

    console.log(`[Job Start] Starting ${fileType} generation for: ${novel.title}`);

    if (fileType === 'epub') {
      // Set headers for EPUB download
      res.setHeader('Content-Type', 'application/epub+zip');
      res.setHeader('Content-Disposition', `attachment; filename="${filename}.epub"`);

      // Pass 'res' as the writable stream.
      // The generator will pipe the .epub zip directly to the user.
      await streamEpub(novel, chapters, res);

    } else if (fileType === 'pdf') {
      // Set headers for PDF download
      res.setHeader('Content-Type', 'application/pdf');
      res.setHeader('Content-Disposition', `attachment; filename="${filename}.pdf"`);

      // Pass 'res' as the writable stream.
      // The generator will pipe the .pdf doc directly to the user.
      await streamPdf(novel, chapters, res);

    } else {
      return res.status(400).json({ error: 'Invalid file type.' });
    }

    console.log(`[Job Success] Finished streaming for: ${novel.title}`);

  } catch (error) {
    console.error('[Job Error] Failed to generate file:', error);
    // If headers haven't been sent, send an error.
    if (!res.headersSent) {
      res.status(500).json({ error: 'Failed to generate file.' });
    }
    // If headers were sent, the stream is already broken.
    // We can just end the response.
    res.end();
  }
});

/**
 * This old in-memory buffering function should be REMOVED.
 * We replace it with the streaming logic above.
 *
 * function processAndGenerate(jobId: string) {
 * // ... old logic that fetches all chapters and stores in memory ...
 * // ... const allContent = ...
 * // ... generateEpub(allContent) ...
 * }
 */

export default router;

server generator Ts

import { Response } from 'express';
import axios from 'axios';
import * as cheerio from 'cheerio';
import archiver from 'archiver';
import PDFDocument from 'pdfkit';
import { NovelMetadata, Chapter } from '../shared/schema';

// Helper to fetch and clean chapter content
// We use a simple retry mechanism
async function fetchAndCleanChapter(url: string, title: string): Promise<string> {
  let attempts = 0;
  while (attempts < 3) {
    try {
      const { data } = await axios.get(url, { timeout: 15000 });
      const $ = cheerio.load(data);

      // --- This query is an EXAMPLE. ---
      // --- You MUST update this selector for your specific novel source. ---
      const content = $('#chapter-content') || $('div.chapter-content') || $('div.entry-content');

      if (content.length) {
        // Basic cleaning
        content.find('script, style, .adsbygoogle').remove();
        
        // Return a full XHTML structure for the EPUB
        return `
          <html xmlns="http://www.w3.org/1999/xhtml">
            <head>
              <title>${title}</title>
            </head>
            <body>
              <h1>${title}</h1>
              ${content.html()}
            </body>
          </html>
        `;
      }
      attempts++;
    } catch (error) {
      console.warn(`[Fetch Retry] Attempt ${attempts + 1} failed for ${url}:`, error.message);
      attempts++;
    }
  }
  // If all retries fail, return a fallback chapter
  console.error(`[Fetch Fail] All attempts failed for ${url}`);
  return `
    <html xmlns="http://www.w3.org/1999/xhtml">
      <head><title>${title}</title></head>
      <body><h1>${title}</h1><p>Error: Could not load chapter content.</p></body>
    </html>
  `;
}

// --- EPUB Streaming Generator ---

export async function streamEpub(novel: NovelMetadata, chapters: Chapter[], res: Response) {
  const archive = archiver('zip', { zlib: { level: 9 } });

  // Good error handling for the stream
  archive.on('warning', (err) => console.warn('[Archiver Warning]', err));
  archive.on('error', (err) => { throw err; });

  // Pipe the archive stream directly to the Express response stream
  archive.pipe(res);

  // 1. Add EPUB mimetype file (must be first and uncompressed)
  archive.append('application/epub+zip', { name: 'mimetype', store: true });

  // 2. Add EPUB container file
  archive.append(getEpubContainer(), { name: 'META-INF/container.xml' });

  // 3. Generate and add metadata files (content.opf, toc.ncx)
  const opfContent = getEpubContentOpf(novel, chapters);
  const ncxContent = getEpubTocNcx(novel, chapters);
  archive.append(opfContent, { name: 'OEBPS/content.opf' });
  archive.append(ncxContent, { name: 'OEBPS/toc.ncx' });

  // 4. Fetch, clean, and stream each chapter one by one
  for (let i = 0; i < chapters.length; i++) {
    const chapter = chapters[i];
    console.log(`[EPUB Stream] Processing chapter ${i + 1}/${chapters.length}: ${chapter.title}`);
    
    // Fetch and clean *only one* chapter
    const chapterHtml = await fetchAndCleanChapter(chapter.url, chapter.title);
    
    // Append it to the zip stream and let it go from memory
    archive.append(chapterHtml, { name: `OEBPS/chapter${i + 1}.xhtml` });
  }

  // 5. Finalize the archive. This signals the end to the 'res' stream.
  await archive.finalize();
}

// --- PDF Streaming Generator ---

export async function streamPdf(novel: NovelMetadata, chapters: Chapter[], res: Response) {
  const doc = new PDFDocument({
    autoFirstPage: false,
    bufferPages: true, // Buffers pages in memory, but not the *content*
  });

  // Pipe the PDF stream directly to the Express response stream
  doc.pipe(res);

  // 1. Add Title Page
  doc.addPage();
  doc.fontSize(24).text(novel.title, { align: 'center' });
  doc.moveDown();
  doc.fontSize(16).text(novel.author, { align: 'center' });
  // You could add the cover image here if you fetch it
  
  // 2. Add Table of Contents (optional, but good)
  doc.addPage().fontSize(20).text('Table of Contents');
  chapters.forEach((chapter, i) => {
    doc.fontSize(12).text(`${i + 1}. ${chapter.title}`);
  });

  // 3. Fetch, clean, and stream each chapter one by one
  for (let i = 0; i < chapters.length; i++) {
    const chapter = chapters[i];
    console.log(`[PDF Stream] Processing chapter ${i + 1}/${chapters.length}: ${chapter.title}`);

    // Fetch and clean chapter
    const chapterHtml = await fetchAndCleanChapter(chapter.url, chapter.title);
    
    // Convert HTML to plain text for PDFKit
    const $ = cheerio.load(chapterHtml);
    const chapterText = $('body').text(); // Get plain text

    // Add a new page for the chapter
    doc.addPage()
       .fontSize(16)
       .text(chapter.title, { align: 'center' })
       .moveDown()
       .fontSize(12)
       .text(chapterText, { align: 'left' });
  }

  // 4. Finalize the PDF. This signals the end to the 'res' stream.
  doc.end();
}


// --- EPUB Helper Functions (Generating metadata files) ---

function getEpubContainer(): string {
  return `<?xml version="1.0" encoding="UTF-8"?>
<container version="1.0" xmlns="urn:oasis:names:tc:opendocument:xmlns:container">
  <rootfiles>
    <rootfile full-path="OEBPS/content.opf" media-type="application/oebps-package+xml"/>
  </rootfiles>
</container>`;
}

function getEpubContentOpf(novel: NovelMetadata, chapters: Chapter[]): string {
  const manifestItems = chapters.map((_, i) => 
    `<item id="chapter${i + 1}" href="chapter${i + 1}.xhtml" media-type="application/xhtml+xml"/>`
  ).join('\n    ');

  const spineItems = chapters.map((_, i) => 
    `<itemref idref="chapter${i + 1}"/>`
  ).join('\n    ');

  return `<?xml version="1.0" encoding="UTF-8"?>
<package xmlns="http://www.idpf.org/2007/opf" unique-identifier="bookid" version="2.0">
  <metadata xmlns:dc="http://purl.org/dc/elements/1.1/">
    <dc:title>${novel.title}</dc:title>
    <dc:creator>${novel.author}</dc:creator>
    <dc:identifier id="bookid">urn:uuid:${Date.now()}</dc:identifier>
    <dc:language>en</dc:language>
  </metadata>
  <manifest>
    <item id="ncx" href="toc.ncx" media-type="application/x-dtbncx+xml"/>
    ${manifestItems}
  </manifest>
  <spine toc="ncx">
    ${spineItems}
  </spine>
</package>`;
}

function getEpubTocNcx(novel: NovelMetadata, chapters: Chapter[]): string {
  const navPoints = chapters.map((chapter, i) => `
    <navPoint id="navPoint-${i + 1}" playOrder="${i + 1}">
      <navLabel><text>${chapter.title}</text></navLabel>
      <content src="chapter${i + 1}.xhtml"/>
    </navPoint>
  `).join('');

  return `<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE ncx PUBLIC "-//NISO//DTD ncx 2005-1//EN" "http://www.daisy.org/z3986/2005/ncx-2005-1.dtd">
<ncx xmlns="http://www.daisy.org/z3986/2005/ncx/" version="2005-1">
  <head>
    <meta name="dtb:uid" content="urn:uuid:${Date.now()}"/>
    <meta name="dtb:depth" content="1"/>
    <meta name="dtb:totalPageCount" content="0"/>
    <meta name="dtb:maxPageNumber" content="0"/>
  </head>
  <docTitle><text>${novel.title}</text></docTitle>
  <navMap>
    ${navPoints}
  </navMap>
</ncx>`;
}

download progress tsx

import React from 'react';
// Assuming you have these components
import { BookOpen, RefreshCw } from 'lucide-react'; 

interface DownloadProgressProps {
  title: string;
  progress: number;
  status: string;
}

export const DownloadProgress: React.FC<DownloadProgressProps> = ({ title, progress, status }) => {
  return (
    <div className="flex items-center gap-3 w-full p-4 bg-gray-800 rounded-lg">
      <BookOpen className="w-6 h-6 text-blue-400 flex-shrink-0" />

      {/* THE FIX: We add `flex-1` and `min-w-0` to this div.
        - `flex-1` tells it to take up the remaining space.
        - `min-w-0` tells it that its minimum width *can* be zero,
          which allows it to shrink and forces its children to wrap.
      */}
      <div className="flex-1 min-w-0">
        <h3 className="font-semibold text-sm text-white break-words line-clamp-2">
          {title}
        </h3>
        <p className="text-xs text-gray-400">{status}</p>
        <div className="w-full bg-gray-700 rounded-full h-1.5 mt-1">
          <div
            className="bg-blue-500 h-1.5 rounded-full"
            style={{ width: `${progress}%` }}
          ></div>
        </div>
      </div>

      <RefreshCw className="w-5 h-5 text-gray-500 animate-spin flex-shrink-0" />
    </div>
  );
};

metadata display tsx

import React from 'react';

interface MetadataDisplayProps {
  novel: {
    title: string;
    author: string;
    coverUrl: string;
    chapterCount: number;
  };
}

export const MetadataDisplay: React.FC<MetadataDisplayProps> = ({ novel }) => {
  return (
    <div className="flex items-start gap-4 p-4 bg-gray-800 rounded-lg">
      <img
        src={novel.coverUrl}
        alt="Novel Cover"
        className="w-20 h-28 object-cover rounded flex-shrink-0"
        onError={(e) => (e.currentTarget.src = 'https://placehold.co/80x112/374151/9ca3af?text=N/A')}
      />

      {/* THE FIX: Same as before. `flex-1` to grow, `min-w-0` to allow shrinking.
        This container holds all the text, forcing it to obey the parent's width.
      */}
      <div className="flex-1 min-w-0">
        <p className="font-semibold text-base text-white break-words line-clamp-2">
          {novel.title}
        </p>
        <p className="text-sm text-gray-400 mt-1">{novel.author}</p>
        <p className="text-sm text-gray-500 mt-1">{novel.chapterCount} chapters</p>
      </div>
    </div>
  );
};


Claude response message:

Hello! Dealing with large data payloads and finicky mobile CSS is a classic full-stack challenge. The 413 error is a hard blocker for large novels, and the horizontal overflow breaks the user experience.

You are correct on both root causes:

Issue 1: You're buffering the entire 2000-chapter novel in memory, which is exceeding the heap limit and the Express request size limit. The solution is to stop buffering and start streaming.

Issue 2: The text-wrapping classes (line-clamp-2, break-words) are being ignored because their parent flex container isn't correctly constrained.

I've prepared the necessary file updates to solve both of these critical issues.

1. Backend: Fixing "413 Request Entity Too Large"
We'll re-architect the backend to stream files directly to the user. Instead of downloading all chapters and then generating the file, we will fetch one chapter at a time, append it to the file stream, and then discard it from memory.

First, here are the packages I'm assuming you have in your package.json. No new packages are required.
package.json (dependencies)
Nov 29, 12:13 PM

Open

This file just removes the content field. The frontend will now only send the list of chapters (URLs and titles), not their content.
shared/schema.ts
Nov 29, 12:13 PM

Open

Here is the updated routes.ts. We've added the Express size limits as a safeguard and changed the /api/download endpoint to a POST request that immediately starts the streaming generation.
server/routes.ts
Nov 29, 12:13 PM

Open

This is the new generator.ts with streaming logic. It fetches one chapter at a time, processes it, adds it to the stream, and discards it.
server/generator.ts
Nov 29, 12:13 PM

Open

2. Frontend: Fixing Mobile Title Overflow
The problem is that a flex item (the container holding your text) will not wrap its content unless it's explicitly told its boundaries. Adding min-w-0 to the flex item that is the parent of the text elements solves this.

Here are the two fixed components:
download-progress.tsx
Nov 29, 12:13 PM

Open
metadata-display.tsx
Nov 29, 12:13 PM

Open

This streaming architecture completely bypasses the memory and request size limits, allowing you to generate files for novels of any size. The CSS fix will ensure your mobile layout is robust and no longer breaks with long titles